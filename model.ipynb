{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Setup and Load Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Install Dependencies and Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision.models.segmentation\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from PIL import Image\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from torchviz import make_dot\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "import tqdm\n",
    "\n",
    "# Set the device to use\n",
    "# CUDA refers to the GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## Hyperparameters\n",
    "num_epochs = 400\n",
    "batch_size = 256\n",
    "\n",
    "## Fixing Random Seed for Reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "\n",
    "# If you are successfully using a GPU, this print should contain \"cuda\" in it\n",
    "print(str(device))\n",
    "assert('cuda' in str(device))  # comment out this assert if you are not using a GPU\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:50<00:00, 90.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# change directory to the data directory\n",
    "os.chdir('../HMEI2023-bxliu-data/')\n",
    "\n",
    "# initialize the lists that store the images and thetas\n",
    "image_list = []\n",
    "theta_list = []\n",
    "\n",
    "# name of directories of the images and values\n",
    "image_directory = 'image_rain'\n",
    "value_directory = 'value_rain'\n",
    "\n",
    "# iterate over files in image directory\n",
    "for filename in tqdm.tqdm(os.listdir(image_directory)):\n",
    "    f = os.path.join(image_directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        # load the image data\n",
    "        # use this for color images (3 channels)\n",
    "        # image = Image.open(f)\n",
    "        # data = np.asarray(image)\n",
    "\n",
    "        # use this for gray scale images (1 channel)\n",
    "        data = cv2.cvtColor(cv2.imread(f), cv2.COLOR_BGR2GRAY)\n",
    "        data = cv2.resize(data, (128,128), interpolation=cv2.INTER_CUBIC)\n",
    "        data = np.expand_dims(data, axis=2)\n",
    "\n",
    "        # load the theta data\n",
    "        matfile = value_directory + '/' + filename[:len(filename) - 4] + '.mat'\n",
    "        mat = scipy.io.loadmat(matfile)\n",
    "\n",
    "        # append to the image and theta lists\n",
    "        image_list.append(data)\n",
    "        theta_list.append(mat['th0'][0])\n",
    "\n",
    "# reformat the lists to make the compatable with what we want to do in Pytorch\n",
    "theta_list = np.asarray(theta_list)\n",
    "image_list = np.asarray(image_list)\n",
    "\n",
    "image_list = np.moveaxis(image_list, -1, 1)\n",
    "\n",
    "image_list = torch.tensor(image_list).float()\n",
    "\n",
    "theta_list = torch.tensor(theta_list)\n",
    "\n",
    "os.chdir('../HMEI2023-bxliu/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.4588, 0.4431, 0.5843,  ..., 0.3961, 0.3961, 0.3961],\n",
      "          [0.4627, 0.4471, 0.5922,  ..., 0.4000, 0.4039, 0.4039],\n",
      "          [0.4275, 0.4196, 0.5059,  ..., 0.3490, 0.3098, 0.3137],\n",
      "          ...,\n",
      "          [0.3490, 0.3412, 0.4275,  ..., 0.5686, 0.2863, 0.3137],\n",
      "          [0.2353, 0.2039, 0.5216,  ..., 0.3961, 0.4314, 0.4275],\n",
      "          [0.2275, 0.1961, 0.5176,  ..., 0.3882, 0.4235, 0.4196]]],\n",
      "\n",
      "\n",
      "        [[[0.4431, 0.4314, 0.5529,  ..., 0.2510, 0.0784, 0.0941],\n",
      "          [0.4431, 0.4314, 0.5490,  ..., 0.2549, 0.0627, 0.0824],\n",
      "          [0.4275, 0.4118, 0.5843,  ..., 0.2039, 0.1882, 0.1882],\n",
      "          ...,\n",
      "          [0.4745, 0.4902, 0.3333,  ..., 0.6314, 0.7765, 0.7608],\n",
      "          [0.4745, 0.5098, 0.1569,  ..., 0.5843, 0.6353, 0.6314],\n",
      "          [0.4706, 0.5059, 0.1490,  ..., 0.5804, 0.6314, 0.6275]]],\n",
      "\n",
      "\n",
      "        [[[0.3647, 0.3804, 0.2196,  ..., 0.4118, 0.3608, 0.3647],\n",
      "          [0.3843, 0.4039, 0.2196,  ..., 0.3922, 0.3569, 0.3608],\n",
      "          [0.1882, 0.1843, 0.2353,  ..., 0.6000, 0.3725, 0.3961],\n",
      "          ...,\n",
      "          [0.2196, 0.2196, 0.2353,  ..., 0.3647, 0.4157, 0.4118],\n",
      "          [0.4118, 0.4078, 0.4431,  ..., 0.5216, 0.4863, 0.4902],\n",
      "          [0.4039, 0.4039, 0.4353,  ..., 0.5176, 0.4824, 0.4863]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.4588, 0.4588, 0.4431,  ..., 0.5216, 0.5569, 0.5529],\n",
      "          [0.4588, 0.4588, 0.4431,  ..., 0.5333, 0.5608, 0.5569],\n",
      "          [0.4745, 0.4745, 0.4588,  ..., 0.4275, 0.5137, 0.5059],\n",
      "          ...,\n",
      "          [0.4745, 0.4627, 0.5686,  ..., 0.4275, 0.4431, 0.4431],\n",
      "          [0.4745, 0.4667, 0.5373,  ..., 0.3961, 0.4118, 0.4118],\n",
      "          [0.4706, 0.4627, 0.5333,  ..., 0.3882, 0.4078, 0.4039]]],\n",
      "\n",
      "\n",
      "        [[[0.4275, 0.4314, 0.3804,  ..., 0.6471, 0.6118, 0.6157],\n",
      "          [0.4314, 0.4353, 0.3804,  ..., 0.6627, 0.6196, 0.6235],\n",
      "          [0.3961, 0.3961, 0.3804,  ..., 0.5216, 0.5373, 0.5373],\n",
      "          ...,\n",
      "          [0.1882, 0.1961, 0.1255,  ..., 0.3137, 0.2627, 0.2667],\n",
      "          [0.2196, 0.2275, 0.1569,  ..., 0.3137, 0.2431, 0.2510],\n",
      "          [0.2118, 0.2196, 0.1490,  ..., 0.3059, 0.2353, 0.2431]]],\n",
      "\n",
      "\n",
      "        [[[0.2039, 0.2039, 0.2196,  ..., 0.6980, 0.7686, 0.7608],\n",
      "          [0.2039, 0.2039, 0.2196,  ..., 0.6980, 0.7725, 0.7647],\n",
      "          [0.2039, 0.2039, 0.2039,  ..., 0.6824, 0.7333, 0.7294],\n",
      "          ...,\n",
      "          [0.2510, 0.2471, 0.2824,  ..., 0.5529, 0.5882, 0.5843],\n",
      "          [0.2824, 0.2824, 0.2980,  ..., 0.5216, 0.5922, 0.5843],\n",
      "          [0.2745, 0.2745, 0.2902,  ..., 0.5176, 0.5882, 0.5804]]]])\n",
      "tensor([[-1.7578,  1.0000, -0.1381],\n",
      "        [-1.7578,  1.0000, -0.1381],\n",
      "        [-1.7578,  1.0000, -0.1381],\n",
      "        ...,\n",
      "        [ 2.7418,  1.0000,  1.1952],\n",
      "        [ 2.7418,  1.0000,  1.1952],\n",
      "        [ 2.7418,  1.0000,  1.1952]])\n"
     ]
    }
   ],
   "source": [
    "# images\n",
    "imean = torch.std(image_list, dim=0)\n",
    "istd = torch.mean(image_list, dim=0)\n",
    "image_tensor = torch.div(image_list, 255).float()\n",
    "print(image_tensor)\n",
    "\n",
    "# theta\n",
    "tmean = torch.std(theta_list, dim=0)\n",
    "tstd = torch.mean(theta_list, dim=0)\n",
    "theta_tensor = torch.div(torch.sub(theta_list, tmean), tstd).float()\n",
    "print(theta_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 Make Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = TensorDataset(image_tensor, theta_tensor)\n",
    "\n",
    "# split data into training, validation, and testing data\n",
    "train, val, test = torch.utils.data.random_split(full_dataset, [0.75, 0.125, 0.125])\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "val_loader = DataLoader(val, batch_size=42, shuffle=False, num_workers=8)\n",
    "test_loader = DataLoader(test, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000001C4FA73DD20>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000001C4FA3D2CE0>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000001C4FA791AE0>\n"
     ]
    }
   ],
   "source": [
    "print(train_loader)\n",
    "print(val_loader)\n",
    "print(test_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Set Up the Convolution Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Make Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, padding=2)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2) \n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, padding=2) \n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5, padding=2) \n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.size_linear = 128*16*16\n",
    "        self.fc1 = nn.Linear(self.size_linear, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 3)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "            x = self.pool1(F.relu(self.conv1(x))) \n",
    "            x = self.pool2(F.relu(self.conv2(x))) \n",
    "            x = self.pool3(F.relu(self.conv3(x)))\n",
    "            x = x.view(-1, self.size_linear) # this flattens x into a 1D vector\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x)) \n",
    "            x = self.fc3(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3])\n"
     ]
    }
   ],
   "source": [
    "# Check if CNN has the correct output shape\n",
    "with torch.no_grad():  # tells PyTorch not to track gradients here\n",
    "    # test_data is 100 random images, 1 channel, 128-by-128\n",
    "    test_data = torch.rand(100,1,128,128)\n",
    "    test_net = ConvNet()\n",
    "    out = test_net.forward(test_data)\n",
    "    # the output should have size (100,3)\n",
    "    print(out.size())\n",
    "    assert(out.size()==(100,3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Make Trainer for Training Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self,net=None,optim=None,loss_function=None, train_loader=None, val_loader=None):\n",
    "        self.net = net\n",
    "        self.optim = optim\n",
    "        self.loss_function = loss_function\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "\n",
    "    def train(self,epochs):\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        for epoch in range(epochs):\n",
    "            epoch_train_loss = 0.0\n",
    "            epoch_val_loss = 0.0\n",
    "            epoch_train_steps = 0\n",
    "            epoch_val_steps = 0\n",
    "            for data in self.train_loader:\n",
    "                \n",
    "                # Moving this batch to GPU\n",
    "                # Note that X has shape (batch_size, number of channels, height, width)\n",
    "                # which is equal to (256,1,128,128) since our default batch_size = 256 and \n",
    "                # the image has only 1 channel\n",
    "                X = data[0].to(device)\n",
    "                y = data[1].to(device)\n",
    "   \n",
    "                # Zero the gradient in the optimizer i.e. self.optim\n",
    "                self.optim.zero_grad()\n",
    "\n",
    "                # Getting the output of the Network\n",
    "                out = self.net(X)\n",
    "\n",
    "                # Computing loss using loss function i.e. self.loss_function\n",
    "                loss = self.loss_function(out, y)\n",
    "\n",
    "                # Backpropagate to compute gradients of parameteres\n",
    "                loss.backward()\n",
    "\n",
    "                # Call the optimizer i.e. self.optim\n",
    "                self.optim.step()\n",
    "\n",
    "                epoch_train_loss += loss.item()\n",
    "                epoch_train_steps += 1\n",
    "            \n",
    "            # validation\n",
    "            self.net.eval()\n",
    "            for data in val_loader:\n",
    "                X = data[0].to(device)\n",
    "                y = data[1].to(device)\n",
    "        \n",
    "                out = self.net(X)\n",
    "                loss = self.loss_function(out, y)\n",
    "                epoch_val_loss += loss.item()\n",
    "                epoch_val_steps += 1\n",
    "\n",
    "            # average loss of epoch\n",
    "            train_losses.append(epoch_train_loss / epoch_train_steps)\n",
    "            print(\"epoch [%d]: train loss %.3f\" % (epoch+1, train_losses[-1]))\n",
    "            val_losses.append(epoch_val_loss / epoch_val_steps)\n",
    "            print(\"epoch [%d]: val loss %.3f\" % (epoch+1, val_losses[-1]))\n",
    "        # return train_losses\n",
    "        return train_losses, val_losses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Train and Evaluate Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1]: train loss 1.218\n",
      "epoch [1]: val loss 1.104\n",
      "epoch [2]: train loss 1.132\n",
      "epoch [2]: val loss 1.089\n",
      "epoch [3]: train loss 1.118\n",
      "epoch [3]: val loss 1.066\n",
      "epoch [4]: train loss 1.086\n",
      "epoch [4]: val loss 1.034\n",
      "epoch [5]: train loss 1.059\n",
      "epoch [5]: val loss 1.020\n",
      "epoch [6]: train loss 1.052\n",
      "epoch [6]: val loss 1.020\n",
      "epoch [7]: train loss 1.051\n",
      "epoch [7]: val loss 1.021\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m loss_function \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n\u001b[0;32m     12\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(net\u001b[39m=\u001b[39mnet, optim\u001b[39m=\u001b[39mopt, loss_function\u001b[39m=\u001b[39mloss_function, train_loader\u001b[39m=\u001b[39mtrain_loader, val_loader\u001b[39m=\u001b[39mval_loader)\n\u001b[1;32m---> 14\u001b[0m train_losses, val_losses \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain(num_epochs)\n",
      "Cell \u001b[1;32mIn[60], line 46\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, epochs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39m# validation\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnet\u001b[39m.\u001b[39meval()\n\u001b[1;32m---> 46\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m val_loader:\n\u001b[0;32m     47\u001b[0m     X \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     48\u001b[0m     y \u001b[39m=\u001b[39m data[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\benli\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\benli\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[0;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[0;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[0;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\benli\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1290\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1293\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m-> 1294\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[0;32m   1295\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m   1296\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\benli\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1120\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m   1133\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[0;32m   1134\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1135\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\benli\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[0;32m    114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[1;32mc:\\Users\\benli\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[0;32m    261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[1;32m--> 262\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[1;32mc:\\Users\\benli\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\connection.py:335\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_got_empty_message \u001b[39mor\u001b[39;00m\n\u001b[0;32m    333\u001b[0m             _winapi\u001b[39m.\u001b[39mPeekNamedPipe(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[0;32m    334\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 335\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(wait([\u001b[39mself\u001b[39;49m], timeout))\n",
      "File \u001b[1;32mc:\\Users\\benli\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\connection.py:884\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    881\u001b[0m                 ready_objects\u001b[39m.\u001b[39madd(o)\n\u001b[0;32m    882\u001b[0m                 timeout \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m--> 884\u001b[0m     ready_handles \u001b[39m=\u001b[39m _exhaustive_wait(waithandle_to_obj\u001b[39m.\u001b[39;49mkeys(), timeout)\n\u001b[0;32m    885\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m     \u001b[39m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     \u001b[39mfor\u001b[39;00m ov \u001b[39min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32mc:\\Users\\benli\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\connection.py:816\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    814\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[0;32m    815\u001b[0m \u001b[39mwhile\u001b[39;00m L:\n\u001b[1;32m--> 816\u001b[0m     res \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mWaitForMultipleObjects(L, \u001b[39mFalse\u001b[39;49;00m, timeout)\n\u001b[0;32m    817\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    818\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#try different learning rates to see which one works \n",
    "learning_rate = 0.00001 # only nu, only sigma, color, gray, constant nu?, constant rho?, constant sigma?, rand 10 by 200\n",
    "# learning_rate = 0.0001 # only rho\n",
    "# learning_rate = 0.0000001 # 5 by 400\n",
    "# learning_rate = 0.000001 # 10 by 200, rand 5 by 400\n",
    "\n",
    "net = ConvNet()\n",
    "net = net.to(device)\n",
    "opt = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "trainer = Trainer(net=net, optim=opt, loss_function=loss_function, train_loader=train_loader, val_loader=val_loader)\n",
    "\n",
    "train_losses, val_losses = trainer.train(num_epochs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Plot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plot the training loss (y-axis) vs epoch number (x-axis) using the losses computed\n",
    "plt.plot(range(1,num_epochs+1), train_losses, color = 'red')\n",
    "plt.plot(range(1,num_epochs+1), val_losses, color = 'blue')\n",
    "plt.xlabel(\"epoch number\")\n",
    "plt.ylabel(\"training loss\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Test Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of all losses and outputs\n",
    "hist_array = []\n",
    "out_array = []\n",
    "\n",
    "# errors for th0(1), th0(2), th0(3) respectively\n",
    "err1 = 0\n",
    "err2 = 0\n",
    "err3 = 0\n",
    "tot = 0\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        # retrieve X and y for this batch, from data, and \n",
    "        # move it to the device you are using (probably the GPU)\n",
    "        X = data[0].to(device)\n",
    "        y = data[1].to(device)\n",
    "\n",
    "        # raw output of network for X\n",
    "        output = net(X)\n",
    "\n",
    "        a = torch.add(torch.mul(output[0], tstd.to(device)), tmean.to(device))\n",
    "        b = torch.add(torch.mul(y[0], tstd.to(device)), tmean.to(device))\n",
    "\n",
    "        print(\"###################################################\")\n",
    "        print(a)\n",
    "        print(b)\n",
    "        print(\"###################################################\")\n",
    "\n",
    "        hist_array.append(a.cpu().numpy() - b.cpu().numpy())\n",
    "        out_array.append(a.cpu().numpy())\n",
    "        \n",
    "        tot += y.size(0)\n",
    "\n",
    "        errors = output.sub(y).multiply(output.sub(y)).div(2).sum(axis=0)\n",
    "        err1 += errors[0]\n",
    "        err2 += errors[1]\n",
    "        err3 += errors[2]\n",
    "        count += 1\n",
    "\n",
    "print(tot)\n",
    "print(err1/count)\n",
    "print(err2/count)\n",
    "print(err3/count)\n",
    "\n",
    "print('Accuracy of prediction on test (1): %5.2f%%' % (100-100 * err1 / tot))\n",
    "\n",
    "print('Accuracy of prediction on test (2): %5.2f%%' % (100-100 * err2 / tot))\n",
    "\n",
    "print('Accuracy of prediction on test (3): %5.2f%%' % (100-100 * err3 / tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 Plot Histograms of Losses and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_array = np.array(hist_array)\n",
    "a = hist_array[:, 0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "ax.hist(a)\n",
    " \n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_array = np.array(out_array)\n",
    "a = out_array[:, 0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "ax.hist(a)\n",
    " \n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = hist_array[:, 1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "ax.hist(a)\n",
    " \n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = out_array[:, 1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "ax.hist(a)\n",
    " \n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = hist_array[:, 2]\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "ax.hist(a)\n",
    " \n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = out_array[:, 2]\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "ax.hist(a)\n",
    " \n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Model as a .pt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('../HMEI2023-bxliu-models/')\n",
    "# save_file = 'only_sigma.pt'\n",
    "# torch.save(net.state_dict(), save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually Representation of the Structure of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torch.rand(1,1,128,128)\n",
    "test_net = ConvNet()\n",
    "out = test_net.forward(test_data)\n",
    "make_dot(out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Steps:\n",
    "custom loss function (later)\n",
    "documentation (done)\n",
    "validation (done-ish, needs going thru again with all the datasets probably)\n",
    "more data (done)\n",
    "graph outputs not just loss (done)\n",
    "outside training set for 5by400 and 10by200 (done-ish)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Make a function that takes in image data and outputs the model's prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "f = '../HMEI2023-bxliu-data/image_rand_10by200/gentrain_1001.png'\n",
    "data = cv2.cvtColor(cv2.imread(f), cv2.COLOR_BGR2GRAY)\n",
    "data = cv2.resize(data, (128,128), interpolation=cv2.INTER_CUBIC)\n",
    "data = np.expand_dims(data, axis=2)\n",
    "print(data.shape)\n",
    "# out = net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_net(im_data):\n",
    "    l = []\n",
    "    l.append(im_data)\n",
    "    l = np.asarray(l)\n",
    "    l = np.moveaxis(l, -1, 1)\n",
    "    print(l.shape)\n",
    "    l = torch.tensor(l).float()\n",
    "    l = torch.div(l, 255).float()\n",
    "    l = l.to(device)\n",
    "    print(l.shape)\n",
    "    print(l)\n",
    "    print(l.stride())\n",
    "    \n",
    "\n",
    "    with torch.no_grad():  \n",
    "        test_data = torch.rand(1,1,128,128).to(device)\n",
    "        test_data[0] = l[0]\n",
    "        print(test_data.shape)\n",
    "        print(test_data)\n",
    "        print(test_data.stride())\n",
    "        out = net.forward(test_data)\n",
    "        # out = net.forward(l)\n",
    "        out = torch.add(torch.mul(out[0], tstd.to(device)), tmean.to(device))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 128, 128)\n",
      "torch.Size([1, 1, 128, 128])\n",
      "tensor([[[[0.7294, 0.7451, 0.6000,  ..., 0.5216, 0.5569, 0.5529],\n",
      "          [0.7412, 0.7569, 0.6039,  ..., 0.5216, 0.5529, 0.5529],\n",
      "          [0.6314, 0.6392, 0.5686,  ..., 0.5373, 0.5725, 0.5686],\n",
      "          ...,\n",
      "          [0.3137, 0.2902, 0.5216,  ..., 0.3804, 0.8549, 0.8078],\n",
      "          [0.4902, 0.4980, 0.4275,  ..., 0.5373, 0.7176, 0.6980],\n",
      "          [0.4863, 0.4902, 0.4196,  ..., 0.5333, 0.7137, 0.6941]]]],\n",
      "       device='cuda:0')\n",
      "(16384, 1, 128, 1)\n",
      "torch.Size([1, 1, 128, 128])\n",
      "tensor([[[[0.7294, 0.7451, 0.6000,  ..., 0.5216, 0.5569, 0.5529],\n",
      "          [0.7412, 0.7569, 0.6039,  ..., 0.5216, 0.5529, 0.5529],\n",
      "          [0.6314, 0.6392, 0.5686,  ..., 0.5373, 0.5725, 0.5686],\n",
      "          ...,\n",
      "          [0.3137, 0.2902, 0.5216,  ..., 0.3804, 0.8549, 0.8078],\n",
      "          [0.4902, 0.4980, 0.4275,  ..., 0.5373, 0.7176, 0.6980],\n",
      "          [0.4863, 0.4902, 0.4196,  ..., 0.5333, 0.7137, 0.6941]]]],\n",
      "       device='cuda:0')\n",
      "(16384, 16384, 128, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2.0585e+06, 1.5562e+00, 6.0079e+03], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_net(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.34650214e+06 2.59287601e+00 4.98000000e+03]\n"
     ]
    }
   ],
   "source": [
    "matfile = '../HMEI2023-bxliu-data/value_rand_10by200/gentrain_1001.mat'\n",
    "mat = scipy.io.loadmat(matfile)\n",
    "print(mat['th0'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
