{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to use colab for gpus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Setup and Load Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Install Dependencies and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision.models.segmentation\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from PIL import Image\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from torchviz import make_dot\n",
    "\n",
    "# Set the device to use\n",
    "# CUDA refers to the GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## Hyperparameters\n",
    "num_epochs = 10\n",
    "num_classes = 10  # there are 10 digits: 0 to 9\n",
    "batch_size = 256\n",
    "\n",
    "## Fixing Random Seed for Reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "\n",
    "# If you are on CoLab and successfully using the GPU, this print should\n",
    "#   contain \"cuda\" in it\n",
    "print(str(device))\n",
    "assert('cuda' in str(device))  # comment out this assert if you are not using a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 99, 204, 111],\n",
       "        [ 99, 204, 111],\n",
       "        [ 99, 204, 111],\n",
       "        ...,\n",
       "        [ 43, 195, 167],\n",
       "        [ 43, 195, 167],\n",
       "        [ 43, 195, 167]],\n",
       "\n",
       "       [[ 99, 204, 111],\n",
       "        [ 99, 204, 111],\n",
       "        [ 99, 204, 111],\n",
       "        ...,\n",
       "        [ 43, 195, 167],\n",
       "        [ 43, 195, 167],\n",
       "        [ 43, 195, 167]],\n",
       "\n",
       "       [[ 99, 204, 111],\n",
       "        [ 99, 204, 111],\n",
       "        [ 99, 204, 111],\n",
       "        ...,\n",
       "        [ 43, 195, 167],\n",
       "        [ 43, 195, 167],\n",
       "        [ 43, 195, 167]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 39, 150, 235],\n",
       "        [ 39, 150, 235],\n",
       "        [ 39, 150, 235],\n",
       "        ...,\n",
       "        [ 45, 134, 246],\n",
       "        [ 45, 134, 246],\n",
       "        [ 45, 134, 246]],\n",
       "\n",
       "       [[ 39, 150, 235],\n",
       "        [ 39, 150, 235],\n",
       "        [ 39, 150, 235],\n",
       "        ...,\n",
       "        [ 45, 134, 246],\n",
       "        [ 45, 134, 246],\n",
       "        [ 45, 134, 246]],\n",
       "\n",
       "       [[ 39, 150, 235],\n",
       "        [ 39, 150, 235],\n",
       "        [ 39, 150, 235],\n",
       "        ...,\n",
       "        [ 45, 134, 246],\n",
       "        [ 45, 134, 246],\n",
       "        [ 45, 134, 246]]], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = cv2.cvtColor(cv2.imread('trainingdataimages/gentrain_001.png'), cv2.COLOR_BGR2RGB)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 99, 204, 111],\n",
       "        [ 99, 204, 111],\n",
       "        [ 99, 204, 111],\n",
       "        ...,\n",
       "        [ 43, 195, 167],\n",
       "        [ 43, 195, 167],\n",
       "        [ 43, 195, 167]],\n",
       "\n",
       "       [[ 99, 204, 111],\n",
       "        [ 99, 204, 111],\n",
       "        [ 99, 204, 111],\n",
       "        ...,\n",
       "        [ 43, 195, 167],\n",
       "        [ 43, 195, 167],\n",
       "        [ 43, 195, 167]],\n",
       "\n",
       "       [[ 99, 204, 111],\n",
       "        [ 99, 204, 111],\n",
       "        [ 99, 204, 111],\n",
       "        ...,\n",
       "        [ 43, 195, 167],\n",
       "        [ 43, 195, 167],\n",
       "        [ 43, 195, 167]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 39, 150, 235],\n",
       "        [ 39, 150, 235],\n",
       "        [ 39, 150, 235],\n",
       "        ...,\n",
       "        [ 45, 134, 246],\n",
       "        [ 45, 134, 246],\n",
       "        [ 45, 134, 246]],\n",
       "\n",
       "       [[ 39, 150, 235],\n",
       "        [ 39, 150, 235],\n",
       "        [ 39, 150, 235],\n",
       "        ...,\n",
       "        [ 45, 134, 246],\n",
       "        [ 45, 134, 246],\n",
       "        [ 45, 134, 246]],\n",
       "\n",
       "       [[ 39, 150, 235],\n",
       "        [ 39, 150, 235],\n",
       "        [ 39, 150, 235],\n",
       "        ...,\n",
       "        [ 45, 134, 246],\n",
       "        [ 45, 134, 246],\n",
       "        [ 45, 134, 246]]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = Image.open('trainingdataimages/gentrain_001.png')\n",
    "data = np.asarray(image)\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "theta: ([,], [0,3], [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:00<00:00, 196.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 500, 3)\n",
      "[1.6e+06 2.5e+00 2.0e+04]\n",
      "(67, 500, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "image_list = []\n",
    "theta_list = []\n",
    "\n",
    "directory = 'trainingdataimages'\n",
    " \n",
    "# iterate over files in\n",
    "# that directory\n",
    "for filename in tqdm.tqdm(os.listdir(directory)):\n",
    "    # print(filename)\n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        # Opens a image in RGB mode\n",
    "        image = Image.open(f)\n",
    "        data = np.asarray(image)\n",
    "        data = cv2.resize(data, (500,500), interpolation=cv2.INTER_LINEAR)\n",
    "        matfile = 'trainingdatavalues/' + filename[:len(filename) - 4] + '.mat'\n",
    "        mat = scipy.io.loadmat(matfile)\n",
    "        image_list.append(data)\n",
    "        theta_list.append(mat['th0'][0])\n",
    "\n",
    "print(image_list[0].shape)\n",
    "print(theta_list[0])\n",
    "\n",
    "theta_list = np.asarray(theta_list)\n",
    "image_list = np.asarray(image_list)\n",
    "\n",
    "# print(theta_list)\n",
    "\n",
    "# print(image_list.shape)\n",
    "\n",
    "image_train, image_test, theta_train, theta_test = train_test_split(image_list, theta_list)\n",
    "\n",
    "print(image_train.shape)\n",
    "\n",
    "image_list = torch.tensor(image_list).float()\n",
    "# print(image_list)\n",
    "theta_list = torch.tensor(theta_list)\n",
    "# print(theta_list)\n",
    "\n",
    "# image_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.5668,  0.9585,  0.2730],\n",
      "          [ 0.5927,  0.9632,  0.2735],\n",
      "          [ 0.5927,  0.9632,  0.2735],\n",
      "          ...,\n",
      "          [-0.2026,  0.9445,  0.5992],\n",
      "          [-0.2053,  0.9431,  0.6005],\n",
      "          [-0.2054,  0.9429,  0.6005]],\n",
      "\n",
      "         [[ 0.5927,  0.9633,  0.2735],\n",
      "          [ 0.6038,  0.9665,  0.2733],\n",
      "          [ 0.6038,  0.9665,  0.2733],\n",
      "          ...,\n",
      "          [-0.2103,  0.9450,  0.5980],\n",
      "          [-0.2132,  0.9438,  0.5995],\n",
      "          [-0.2133,  0.9434,  0.5995]],\n",
      "\n",
      "         [[ 0.5927,  0.9632,  0.2735],\n",
      "          [ 0.6038,  0.9665,  0.2733],\n",
      "          [ 0.6038,  0.9665,  0.2733],\n",
      "          ...,\n",
      "          [-0.2103,  0.9450,  0.5980],\n",
      "          [-0.2134,  0.9436,  0.5993],\n",
      "          [-0.2133,  0.9434,  0.5995]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3078,  0.6702,  1.0589],\n",
      "          [-0.3202,  0.6733,  1.0613],\n",
      "          [-0.3202,  0.6733,  1.0613],\n",
      "          ...,\n",
      "          [-0.3211,  0.5814,  1.0410],\n",
      "          [-0.3313,  0.5828,  1.0431],\n",
      "          [-0.3322,  0.5828,  1.0433]],\n",
      "\n",
      "         [[-0.3087,  0.6700,  1.0586],\n",
      "          [-0.3210,  0.6732,  1.0611],\n",
      "          [-0.3210,  0.6732,  1.0611],\n",
      "          ...,\n",
      "          [-0.3220,  0.5805,  1.0406],\n",
      "          [-0.3317,  0.5823,  1.0429],\n",
      "          [-0.3328,  0.5824,  1.0429]],\n",
      "\n",
      "         [[-0.3086,  0.6700,  1.0586],\n",
      "          [-0.3210,  0.6732,  1.0611],\n",
      "          [-0.3210,  0.6732,  1.0611],\n",
      "          ...,\n",
      "          [-0.3220,  0.5805,  1.0406],\n",
      "          [-0.3317,  0.5823,  1.0429],\n",
      "          [-0.3328,  0.5824,  1.0429]]],\n",
      "\n",
      "\n",
      "        [[[-0.2232,  0.5626,  1.0410],\n",
      "          [-0.2281,  0.5650,  1.0446],\n",
      "          [-0.2281,  0.5650,  1.0446],\n",
      "          ...,\n",
      "          [-0.3386,  0.7441,  0.9324],\n",
      "          [-0.3410,  0.7431,  0.9347],\n",
      "          [-0.3411,  0.7429,  0.9348]],\n",
      "\n",
      "         [[-0.2281,  0.5650,  1.0446],\n",
      "          [-0.2501,  0.5658,  1.0477],\n",
      "          [-0.2501,  0.5658,  1.0477],\n",
      "          ...,\n",
      "          [-0.3517,  0.7433,  0.9330],\n",
      "          [-0.3545,  0.7424,  0.9355],\n",
      "          [-0.3544,  0.7421,  0.9355]],\n",
      "\n",
      "         [[-0.2281,  0.5650,  1.0446],\n",
      "          [-0.2501,  0.5658,  1.0477],\n",
      "          [-0.2501,  0.5658,  1.0477],\n",
      "          ...,\n",
      "          [-0.3517,  0.7433,  0.9330],\n",
      "          [-0.3546,  0.7423,  0.9353],\n",
      "          [-0.3544,  0.7421,  0.9355]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5450,  0.9644,  0.2977],\n",
      "          [ 0.5586,  0.9689,  0.2942],\n",
      "          [ 0.5586,  0.9689,  0.2942],\n",
      "          ...,\n",
      "          [ 1.4753,  0.9344, -0.1499],\n",
      "          [ 1.4584,  0.9354, -0.1504],\n",
      "          [ 1.4564,  0.9353, -0.1504]],\n",
      "\n",
      "         [[ 0.5448,  0.9643,  0.2976],\n",
      "          [ 0.5585,  0.9688,  0.2942],\n",
      "          [ 0.5585,  0.9688,  0.2942],\n",
      "          ...,\n",
      "          [ 1.4724,  0.9337, -0.1506],\n",
      "          [ 1.4554,  0.9350, -0.1507],\n",
      "          [ 1.4533,  0.9350, -0.1508]],\n",
      "\n",
      "         [[ 0.5449,  0.9643,  0.2976],\n",
      "          [ 0.5585,  0.9688,  0.2942],\n",
      "          [ 0.5585,  0.9688,  0.2942],\n",
      "          ...,\n",
      "          [ 1.4724,  0.9337, -0.1506],\n",
      "          [ 1.4554,  0.9351, -0.1507],\n",
      "          [ 1.4533,  0.9350, -0.1508]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1572,  0.2006,  0.9784],\n",
      "          [ 0.1671,  0.2010,  0.9818],\n",
      "          [ 0.1671,  0.2010,  0.9818],\n",
      "          ...,\n",
      "          [-0.1686,  0.5952,  1.0307],\n",
      "          [-0.1713,  0.5945,  1.0334],\n",
      "          [-0.1714,  0.5944,  1.0335]],\n",
      "\n",
      "         [[ 0.1671,  0.2009,  0.9818],\n",
      "          [ 0.1610,  0.1995,  0.9846],\n",
      "          [ 0.1610,  0.1995,  0.9846],\n",
      "          ...,\n",
      "          [-0.1750,  0.5934,  1.0318],\n",
      "          [-0.1779,  0.5928,  1.0347],\n",
      "          [-0.1780,  0.5925,  1.0347]],\n",
      "\n",
      "         [[ 0.1671,  0.2010,  0.9818],\n",
      "          [ 0.1610,  0.1995,  0.9846],\n",
      "          [ 0.1610,  0.1995,  0.9846],\n",
      "          ...,\n",
      "          [-0.1750,  0.5934,  1.0318],\n",
      "          [-0.1781,  0.5927,  1.0345],\n",
      "          [-0.1780,  0.5925,  1.0347]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.7481,  0.9154, -0.0400],\n",
      "          [ 2.8287,  0.9196, -0.0460],\n",
      "          [ 2.8287,  0.9196, -0.0460],\n",
      "          ...,\n",
      "          [-0.2565,  0.5188,  1.0771],\n",
      "          [-0.2669,  0.5203,  1.0793],\n",
      "          [-0.2679,  0.5203,  1.0795]],\n",
      "\n",
      "         [[ 2.7497,  0.9153, -0.0400],\n",
      "          [ 2.8304,  0.9195, -0.0460],\n",
      "          [ 2.8304,  0.9195, -0.0460],\n",
      "          ...,\n",
      "          [-0.2574,  0.5179,  1.0767],\n",
      "          [-0.2675,  0.5197,  1.0791],\n",
      "          [-0.2686,  0.5198,  1.0791]],\n",
      "\n",
      "         [[ 2.7498,  0.9153, -0.0400],\n",
      "          [ 2.8304,  0.9195, -0.0460],\n",
      "          [ 2.8304,  0.9195, -0.0460],\n",
      "          ...,\n",
      "          [-0.2574,  0.5179,  1.0767],\n",
      "          [-0.2675,  0.5198,  1.0791],\n",
      "          [-0.2686,  0.5198,  1.0791]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0255,  0.9415,  0.8590],\n",
      "          [-0.4409,  0.8950,  0.8276],\n",
      "          [-0.4409,  0.8950,  0.8276],\n",
      "          ...,\n",
      "          [ 3.0269,  0.9445,  0.0693],\n",
      "          [ 3.0193,  0.9431,  0.0690],\n",
      "          [ 3.0186,  0.9429,  0.0690]],\n",
      "\n",
      "         [[-0.4409,  0.8950,  0.8276],\n",
      "          [-0.9616,  0.8463,  0.7895],\n",
      "          [-0.9616,  0.8463,  0.7895],\n",
      "          ...,\n",
      "          [ 3.0942,  0.8932, -0.0719],\n",
      "          [ 3.0874,  0.8920, -0.0725],\n",
      "          [ 3.0854,  0.8916, -0.0726]],\n",
      "\n",
      "         [[-0.4409,  0.8950,  0.8276],\n",
      "          [-0.9616,  0.8463,  0.7895],\n",
      "          [-0.9616,  0.8463,  0.7895],\n",
      "          ...,\n",
      "          [ 3.0942,  0.8932, -0.0719],\n",
      "          [ 3.0879,  0.8918, -0.0726],\n",
      "          [ 3.0854,  0.8916, -0.0726]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.6202,  1.1334, -0.0031],\n",
      "          [ 2.6823,  1.1221, -0.1697],\n",
      "          [ 2.6823,  1.1221, -0.1697],\n",
      "          ...,\n",
      "          [ 1.1264,  0.9572, -0.0416],\n",
      "          [ 1.1108,  0.9582, -0.0419],\n",
      "          [ 1.1090,  0.9581, -0.0419]],\n",
      "\n",
      "         [[ 2.6216,  1.1333, -0.0031],\n",
      "          [ 2.6839,  1.1221, -0.1697],\n",
      "          [ 2.6839,  1.1221, -0.1697],\n",
      "          ...,\n",
      "          [ 1.1238,  0.9565, -0.0423],\n",
      "          [ 1.1083,  0.9577, -0.0422],\n",
      "          [ 1.1064,  0.9578, -0.0423]],\n",
      "\n",
      "         [[ 2.6217,  1.1333, -0.0031],\n",
      "          [ 2.6839,  1.1221, -0.1697],\n",
      "          [ 2.6839,  1.1221, -0.1697],\n",
      "          ...,\n",
      "          [ 1.1238,  0.9565, -0.0423],\n",
      "          [ 1.1083,  0.9578, -0.0422],\n",
      "          [ 1.1064,  0.9578, -0.0423]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2011,  0.9076,  0.9158],\n",
      "          [-0.2129,  0.8665,  0.8904],\n",
      "          [-0.2129,  0.8665,  0.8904],\n",
      "          ...,\n",
      "          [ 0.1034,  0.9789,  0.6920],\n",
      "          [ 0.1002,  0.9774,  0.6936],\n",
      "          [ 0.1001,  0.9772,  0.6937]],\n",
      "\n",
      "         [[-0.2129,  0.8666,  0.8904],\n",
      "          [-0.6928,  0.8120,  0.8641],\n",
      "          [-0.6928,  0.8120,  0.8641],\n",
      "          ...,\n",
      "          [-0.3517,  0.9335,  0.6365],\n",
      "          [-0.3545,  0.9323,  0.6381],\n",
      "          [-0.3544,  0.9319,  0.6380]],\n",
      "\n",
      "         [[-0.2129,  0.8665,  0.8904],\n",
      "          [-0.6928,  0.8120,  0.8641],\n",
      "          [-0.6928,  0.8120,  0.8641],\n",
      "          ...,\n",
      "          [-0.3517,  0.9335,  0.6365],\n",
      "          [-0.3546,  0.9321,  0.6379],\n",
      "          [-0.3544,  0.9319,  0.6380]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5399,  0.9808,  0.1626],\n",
      "          [ 1.4080,  0.9470,  0.0158],\n",
      "          [ 1.4080,  0.9470,  0.0158],\n",
      "          ...,\n",
      "          [-0.6829,  0.8262,  0.8486],\n",
      "          [-0.6918,  0.8274,  0.8502],\n",
      "          [-0.6925,  0.8273,  0.8504]],\n",
      "\n",
      "         [[ 1.5406,  0.9807,  0.1626],\n",
      "          [ 1.4086,  0.9469,  0.0158],\n",
      "          [ 1.4086,  0.9469,  0.0158],\n",
      "          ...,\n",
      "          [-0.6834,  0.8255,  0.8481],\n",
      "          [-0.6917,  0.8269,  0.8500],\n",
      "          [-0.6926,  0.8269,  0.8500]],\n",
      "\n",
      "         [[ 1.5264,  0.9807,  0.1626],\n",
      "          [ 1.4086,  0.9469,  0.0158],\n",
      "          [ 1.4086,  0.9469,  0.0158],\n",
      "          ...,\n",
      "          [-0.6834,  0.8255,  0.8481],\n",
      "          [-0.6917,  0.8270,  0.8500],\n",
      "          [-0.6926,  0.8269,  0.8500]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2889,  0.9698,  0.7679],\n",
      "          [-0.1217,  0.9348,  0.7248],\n",
      "          [-0.1217,  0.9348,  0.7248],\n",
      "          ...,\n",
      "          [ 0.2563,  0.6811,  1.0362],\n",
      "          [ 0.2530,  0.6802,  1.0389],\n",
      "          [ 0.2528,  0.6801,  1.0390]],\n",
      "\n",
      "         [[-0.1217,  0.9348,  0.7248],\n",
      "          [-0.5821,  0.8921,  0.6748],\n",
      "          [-0.5821,  0.8921,  0.6748],\n",
      "          ...,\n",
      "          [-0.1750,  0.5934,  1.0318],\n",
      "          [-0.1779,  0.5928,  1.0347],\n",
      "          [-0.1780,  0.5925,  1.0347]],\n",
      "\n",
      "         [[-0.1217,  0.9348,  0.7248],\n",
      "          [-0.5821,  0.8921,  0.6748],\n",
      "          [-0.5821,  0.8921,  0.6748],\n",
      "          ...,\n",
      "          [-0.1750,  0.5934,  1.0318],\n",
      "          [-0.1781,  0.5927,  1.0345],\n",
      "          [-0.1780,  0.5925,  1.0347]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4073,  0.9154,  0.8563],\n",
      "          [-0.8767,  0.8703,  0.8138],\n",
      "          [-0.8767,  0.8703,  0.8138],\n",
      "          ...,\n",
      "          [ 0.5577,  0.9800,  0.1569],\n",
      "          [ 0.5443,  0.9809,  0.1570],\n",
      "          [ 0.5428,  0.9808,  0.1571]],\n",
      "\n",
      "         [[-0.4082,  0.9153,  0.8561],\n",
      "          [-0.8780,  0.8703,  0.8137],\n",
      "          [-0.8780,  0.8703,  0.8137],\n",
      "          ...,\n",
      "          [ 0.5558,  0.9793,  0.1562],\n",
      "          [ 0.5425,  0.9805,  0.1567],\n",
      "          [ 0.5410,  0.9805,  0.1567]],\n",
      "\n",
      "         [[-0.4081,  0.9153,  0.8561],\n",
      "          [-0.8780,  0.8703,  0.8137],\n",
      "          [-0.8780,  0.8703,  0.8137],\n",
      "          ...,\n",
      "          [ 0.5558,  0.9793,  0.1562],\n",
      "          [ 0.5425,  0.9806,  0.1567],\n",
      "          [ 0.5410,  0.9805,  0.1567]]]])\n",
      "tensor([[0.0363, 0.9351, 0.7630],\n",
      "        [0.0680, 0.9351, 0.7630],\n",
      "        [0.0996, 0.9351, 0.7630],\n",
      "        [0.1312, 0.9351, 0.7630],\n",
      "        [0.1629, 0.9351, 0.7630],\n",
      "        [0.1945, 0.9351, 0.7630],\n",
      "        [0.2261, 0.9351, 0.7630],\n",
      "        [0.2578, 0.9351, 0.7630],\n",
      "        [0.2894, 0.9351, 0.7630],\n",
      "        [0.3210, 0.9351, 0.7630],\n",
      "        [0.3527, 0.9351, 0.7630],\n",
      "        [0.3843, 0.9351, 0.7630],\n",
      "        [0.4159, 0.9351, 0.7630],\n",
      "        [0.4476, 0.9351, 0.7630],\n",
      "        [0.4792, 0.9351, 0.7630],\n",
      "        [0.5108, 0.9351, 0.7630],\n",
      "        [0.5425, 0.9351, 0.7630],\n",
      "        [0.5741, 0.9351, 0.7630],\n",
      "        [0.6057, 0.9351, 0.7630],\n",
      "        [0.6374, 0.9351, 0.7630],\n",
      "        [0.6690, 0.9351, 0.7630],\n",
      "        [0.7006, 0.9351, 0.7630],\n",
      "        [0.7323, 0.9351, 0.7630],\n",
      "        [0.7639, 0.9351, 0.7630],\n",
      "        [0.7955, 0.9351, 0.7630],\n",
      "        [0.8272, 0.9351, 0.7630],\n",
      "        [0.8588, 0.9351, 0.7630],\n",
      "        [0.8905, 0.9351, 0.7630],\n",
      "        [0.9221, 0.9351, 0.7630],\n",
      "        [0.9537, 0.9351, 0.7630],\n",
      "        [0.9854, 0.9351, 0.7630],\n",
      "        [1.0170, 0.9351, 0.7630],\n",
      "        [1.0486, 0.9351, 0.7630],\n",
      "        [1.0803, 0.9351, 0.7630],\n",
      "        [1.1119, 0.9351, 0.7630],\n",
      "        [1.1435, 0.9351, 0.7630],\n",
      "        [1.1752, 0.9351, 0.7630],\n",
      "        [1.2068, 0.9351, 0.7630],\n",
      "        [1.2384, 0.9351, 0.7630],\n",
      "        [1.2701, 0.9351, 0.7630],\n",
      "        [1.3017, 0.9351, 0.7630],\n",
      "        [1.3333, 0.9351, 0.7630],\n",
      "        [1.3650, 0.9351, 0.7630],\n",
      "        [1.3966, 0.9351, 0.7630],\n",
      "        [1.4282, 0.9351, 0.7630],\n",
      "        [1.4599, 0.9351, 0.7630],\n",
      "        [1.4915, 0.9351, 0.7630],\n",
      "        [1.5231, 0.9351, 0.7630],\n",
      "        [1.5548, 0.9351, 0.7630],\n",
      "        [1.5864, 0.9351, 0.7630],\n",
      "        [0.0363, 0.9351, 0.7630],\n",
      "        [0.0680, 0.9351, 0.7630],\n",
      "        [0.0996, 0.9351, 0.7630],\n",
      "        [0.1312, 0.9351, 0.7630],\n",
      "        [0.1629, 0.9351, 0.7630],\n",
      "        [0.1945, 0.9351, 0.7630],\n",
      "        [0.2261, 0.9351, 0.7630],\n",
      "        [0.2578, 0.9351, 0.7630],\n",
      "        [0.2894, 0.9351, 0.7630],\n",
      "        [0.3210, 0.9351, 0.7630],\n",
      "        [0.0363, 0.4735, 0.7630],\n",
      "        [0.0680, 0.4735, 0.7630],\n",
      "        [0.0996, 0.4735, 0.7630],\n",
      "        [0.1312, 0.4735, 0.7630],\n",
      "        [0.1629, 0.4735, 0.7630],\n",
      "        [0.1945, 0.4735, 0.7630],\n",
      "        [0.2261, 0.4735, 0.7630],\n",
      "        [0.2578, 0.4735, 0.7630],\n",
      "        [0.2894, 0.4735, 0.7630],\n",
      "        [0.3210, 0.4735, 0.7630],\n",
      "        [0.0363, 0.4735, 0.2630],\n",
      "        [0.0680, 0.4735, 0.2630],\n",
      "        [0.0996, 0.4735, 0.2630],\n",
      "        [0.1312, 0.4735, 0.2630],\n",
      "        [0.1629, 0.4735, 0.2630],\n",
      "        [0.1945, 0.4735, 0.2630],\n",
      "        [0.2261, 0.4735, 0.2630],\n",
      "        [0.2578, 0.4735, 0.2630],\n",
      "        [0.2894, 0.4735, 0.2630],\n",
      "        [0.3210, 0.4735, 0.2630],\n",
      "        [0.0363, 0.4735, 1.2630],\n",
      "        [0.0680, 0.4735, 1.2630],\n",
      "        [0.0996, 0.4735, 1.2630],\n",
      "        [0.1312, 0.4735, 1.2630],\n",
      "        [0.1629, 0.4735, 1.2630],\n",
      "        [0.1945, 0.4735, 1.2630],\n",
      "        [0.2261, 0.4735, 1.2630],\n",
      "        [0.2578, 0.4735, 1.2630],\n",
      "        [0.2894, 0.4735, 1.2630],\n",
      "        [0.3210, 0.4735, 1.2630]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# normalize data:\n",
    "\n",
    "# images\n",
    "imean = torch.std(image_list, dim=0)\n",
    "istd = torch.mean(image_list, dim=0)\n",
    "image_tensor = torch.div(torch.sub(image_list, imean), istd)\n",
    "print(image_tensor)\n",
    "\n",
    "# theta\n",
    "tmean = torch.std(theta_list, dim=0)\n",
    "tstd = torch.mean(theta_list, dim=0)\n",
    "theta_tensor = torch.div(torch.sub(theta_list, tmean), tstd)\n",
    "print(theta_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.TensorDataset object at 0x0000028B018DA200>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x0000028B018DA710>\n"
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset(image_list, theta_list)\n",
    "print(dataset)\n",
    "train_loader = DataLoader(dataset, batch_size=2, shuffle=False)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5, padding=2)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2) \n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, padding=2) \n",
    "        self.pool2 = nn.MaxPool2d(2, 2) \n",
    "\n",
    "        self.size_linear = 64*125*125\n",
    "        self.fc1 = nn.Linear(self.size_linear, 512)\n",
    "        self.fc2 = nn.Linear(512, 10) # ACT6\n",
    "\n",
    "    def forward(self, x):\n",
    "            x = self.pool1(F.relu(self.conv1(x))) # we provide this line for you\n",
    "            x = self.pool2(F.relu(self.conv2(x))) # ACT7: apply the second convolution and max pooling\n",
    "            x = x.view(-1, self.size_linear) # this flattens x into a 1D vector\n",
    "            x = F.relu(self.fc1(x)) # ACT8: Apply the first fully connected layer and ReLU\n",
    "            x = self.fc2(x) # ACT9: Apply the second fully connected layer (no ReLU)\n",
    "            return x\n",
    "    \n",
    "##ASSERT: checks if your CNN has the correct output shape\n",
    "with torch.no_grad():  # tells PyTorch not to track gradients here\n",
    "    # test_data is 100 random images, 1 channel, 28-by-28\n",
    "    test_data = torch.rand(100,3,500,500)\n",
    "    test_net = ConvNet()\n",
    "    out = test_net.forward(test_data)\n",
    "    # the output should have size (100,10)\n",
    "    assert(out.size()==(100,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = torch.rand(100,3,500,500)\n",
    "# test_net = ConvNet()\n",
    "# out = test_net.forward(test_data)\n",
    "# make_dot(out)  # ACT10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ACT11-ACT15 Please fill the code below\n",
    "class Trainer():\n",
    "    def __init__(self,net=None,optim=None,loss_function=None, train_loader=None):\n",
    "        self.net = net\n",
    "        self.optim = optim\n",
    "        self.loss_function = loss_function\n",
    "        self.train_loader = train_loader\n",
    "\n",
    "    def train(self,epochs):\n",
    "        losses = []\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0.0\n",
    "            epoch_steps = 0\n",
    "            for data in self.train_loader:\n",
    "                \n",
    "                # Moving this batch to GPU\n",
    "                # Note that X has shape (batch_size, number of channels, height, width)\n",
    "                # which is equal to (256,1,28,28) since our default batch_size = 256 and \n",
    "                # the image has only 1 channel\n",
    "                X = data[0].to(device)\n",
    "                y = data[1].to(device)\n",
    "                \n",
    "                # ACT11-Zero the gradient in the optimizer i.e. self.optim\n",
    "                ################\n",
    "                # Your code here\n",
    "                self.optim.zero_grad()\n",
    "                ################\n",
    "\n",
    "                # ACT12-Getting the output of the Network\n",
    "                ################\n",
    "                # Your code here\n",
    "                out = self.net(X)\n",
    "                ################\n",
    "\n",
    "                # ACT13-Computing loss using loss function i.e. self.loss_function\n",
    "                ################\n",
    "                # Your code here\n",
    "                loss = self.loss_function(out, y)\n",
    "                ################\n",
    "\n",
    "                # ACT14-Backpropagate to compute gradients of parameteres\n",
    "                ################\n",
    "                # Your code here\n",
    "                loss.backward()\n",
    "                ################\n",
    "\n",
    "                # ACT15-Call the optimizer i.e. self.optim\n",
    "                ################\n",
    "                # Your code here\n",
    "                self.optim.step()\n",
    "                ################\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                epoch_steps += 1\n",
    "            # average loss of epoch\n",
    "            losses.append(epoch_loss / epoch_steps)\n",
    "            print(\"epoch [%d]: loss %.3f\" % (epoch+1, losses[-1]))\n",
    "        return losses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
