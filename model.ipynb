{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Setup and Load Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Install Dependencies and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision.models.segmentation\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from PIL import Image\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from torchviz import make_dot\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "\n",
    "# Set the device to use\n",
    "# CUDA refers to the GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## Hyperparameters\n",
    "num_epochs = 400\n",
    "batch_size = 256\n",
    "\n",
    "## Fixing Random Seed for Reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "\n",
    "# If you are on CoLab and successfully using the GPU, this print should\n",
    "#   contain \"cuda\" in it\n",
    "print(str(device))\n",
    "assert('cuda' in str(device))  # comment out this assert if you are not using a GPU\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "os.chdir('../HMEI2023-bxliu-data/')\n",
    "\n",
    "image_list = []\n",
    "theta_list = []\n",
    "\n",
    "image_directory = 'image_cats'\n",
    "value_directory = 'value_cats/'\n",
    "\n",
    "# iterate over files in\n",
    "# that directory\n",
    "for filename in tqdm.tqdm(os.listdir(image_directory)):\n",
    "    # print(filename)\n",
    "    f = os.path.join(image_directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        # color\n",
    "        # image = Image.open(f)\n",
    "        # data = np.asarray(image)\n",
    "\n",
    "        # gray scale\n",
    "        data = cv2.cvtColor(cv2.imread(f), cv2.COLOR_BGR2GRAY)\n",
    "        data = cv2.resize(data, (128,128), interpolation=cv2.INTER_CUBIC)\n",
    "        data = np.expand_dims(data, axis=2)\n",
    "\n",
    "        matfile = value_directory + filename[:len(filename) - 4] + '.mat'\n",
    "        mat = scipy.io.loadmat(matfile)\n",
    "        image_list.append(data)\n",
    "        theta_list.append(mat['th0'][0])\n",
    "\n",
    "print(image_list[0].shape)\n",
    "print(theta_list[0])\n",
    "\n",
    "theta_list = np.asarray(theta_list)\n",
    "image_list = np.asarray(image_list)\n",
    "\n",
    "image_list = np.moveaxis(image_list, -1, 1)\n",
    "theta_list = np.moveaxis(theta_list, -1, 1)\n",
    "\n",
    "print(image_list.shape)\n",
    "\n",
    "image_list = torch.tensor(image_list).float()\n",
    "\n",
    "theta_list = torch.tensor(theta_list)\n",
    "\n",
    "os.chdir('../HMEI2023-bxliu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data:\n",
    "\n",
    "# images\n",
    "imean = torch.std(image_list, dim=0)\n",
    "istd = torch.mean(image_list, dim=0)\n",
    "# image_tensor = torch.div(torch.sub(image_list, imean), istd)\n",
    "image_tensor = torch.div(image_list, 255).float()\n",
    "print(image_tensor)\n",
    "\n",
    "# theta\n",
    "tmean = torch.std(theta_list, dim=0)\n",
    "tstd = torch.mean(theta_list, dim=0)\n",
    "theta_tensor = torch.div(torch.sub(theta_list, tmean), tstd).float()\n",
    "# theta_tensor = theta_list.float()\n",
    "print(theta_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = TensorDataset(image_tensor, theta_tensor)\n",
    "\n",
    "train, val, test = torch.utils.data.random_split(full_dataset, [0.75, 0.125, 0.125])\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "val_loader = DataLoader(val, batch_size=42, shuffle=False, num_workers=8)\n",
    "test_loader = DataLoader(test, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_loader)\n",
    "print(val_loader)\n",
    "print(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_train, image_test, theta_train, theta_test = train_test_split(image_tensor, theta_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(image_train))\n",
    "# print(len(image_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = TensorDataset(image_train, theta_train)\n",
    "# print(train_dataset)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "# print(train_loader)\n",
    "\n",
    "# test_dataset = TensorDataset(image_test, theta_test)\n",
    "# print(test_dataset)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "# print(test_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, padding=2)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2) \n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, padding=2) \n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5, padding=2) \n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.size_linear = 128*16*16\n",
    "        self.fc1 = nn.Linear(self.size_linear, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 3)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "            x = self.pool1(F.relu(self.conv1(x))) \n",
    "            x = self.pool2(F.relu(self.conv2(x))) \n",
    "            x = self.pool3(F.relu(self.conv3(x)))\n",
    "            x = x.view(-1, self.size_linear) # this flattens x into a 1D vector\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x)) \n",
    "            x = self.fc3(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ASSERT: checks if CNN has the correct output shape\n",
    "with torch.no_grad():  # tells PyTorch not to track gradients here\n",
    "    # test_data is 100 random images, 1 channel, 128-by-128\n",
    "    test_data = torch.rand(100,1,128,128)\n",
    "    test_net = ConvNet()\n",
    "    out = test_net.forward(test_data)\n",
    "    # the output should have size (100,3)\n",
    "    print(out)\n",
    "    print(out.size())\n",
    "    assert(out.size()==(100,3))\n",
    "\n",
    "    print(out[0][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make trainer for training network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self,net=None,optim=None,loss_function=None, train_loader=None, val_loader=None):\n",
    "        self.net = net\n",
    "        self.optim = optim\n",
    "        self.loss_function = loss_function\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "\n",
    "    def train(self,epochs):\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        for epoch in range(epochs):\n",
    "            epoch_train_loss = 0.0\n",
    "            epoch_val_loss = 0.0\n",
    "            epoch_train_steps = 0\n",
    "            epoch_val_steps = 0\n",
    "            for data in self.train_loader:\n",
    "                \n",
    "                # Moving this batch to GPU\n",
    "                # Note that X has shape (batch_size, number of channels, height, width)\n",
    "                # which is equal to (256,3,128,128) since our default batch_size = 256 and \n",
    "                # the image has only 1 channel\n",
    "                X = data[0].to(device)\n",
    "                y = data[1].to(device)\n",
    "                \n",
    "                # print(X[0])\n",
    "                # plt.imshow(np.moveaxis(X[0].cpu().numpy(), 0, -1))\n",
    "\n",
    "                \n",
    "                # Zero the gradient in the optimizer i.e. self.optim\n",
    "                self.optim.zero_grad()\n",
    "\n",
    "                # Getting the output of the Network\n",
    "                out = self.net(X)\n",
    "\n",
    "                # Computing loss using loss function i.e. self.loss_function\n",
    "                loss = self.loss_function(out, y)\n",
    "\n",
    "                # Backpropagate to compute gradients of parameteres\n",
    "                loss.backward()\n",
    "\n",
    "                # Call the optimizer i.e. self.optim\n",
    "                self.optim.step()\n",
    "\n",
    "                epoch_train_loss += loss.item()\n",
    "                epoch_train_steps += 1\n",
    "            \n",
    "            # validation\n",
    "            self.net.eval()\n",
    "            for data in val_loader:\n",
    "                X = data[0].to(device)\n",
    "                y = data[1].to(device)\n",
    "        \n",
    "                out = self.net(X)\n",
    "                loss = self.loss_function(out, y)\n",
    "                epoch_val_loss += loss.item()\n",
    "                epoch_val_steps += 1\n",
    "\n",
    "            # average loss of epoch\n",
    "            train_losses.append(epoch_train_loss / epoch_train_steps)\n",
    "            print(\"epoch [%d]: train loss %.3f\" % (epoch+1, train_losses[-1]))\n",
    "            val_losses.append(epoch_val_loss / epoch_val_steps)\n",
    "            print(\"epoch [%d]: val loss %.3f\" % (epoch+1, val_losses[-1]))\n",
    "        # return train_losses\n",
    "        return train_losses, val_losses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### try different learning rates for SGD to see which one works (do not try learning rates greater than 1)\n",
    "### we want the last epoch loss to be less than 0.03\n",
    "# learning_rate = 0.00001 # only nu, only sigma, color, gray, constant nu?, constant rho?, constant sigma?, rand 10 by 200\n",
    "learning_rate = 0.0001 # only rho\n",
    "# learning_rate = 0.0000001 # 5 by 400\n",
    "# learning_rate = 0.000001 # 10 by 200, rand 5 by 400\n",
    "\n",
    "net = ConvNet()\n",
    "net = net.to(device)\n",
    "# opt = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "opt = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "trainer = Trainer(net=net, optim=opt, loss_function=loss_function, train_loader=train_loader, val_loader=val_loader)\n",
    "\n",
    "train_losses, val_losses = trainer.train(num_epochs)\n",
    "# train_losses = trainer.train(num_epochs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "### plot the training loss (y-axis) vs epoch number (x-axis)\n",
    "### using the losses computed\n",
    "plt.plot(range(1,num_epochs+1), train_losses, color = 'red')\n",
    "plt.plot(range(1,num_epochs+1), val_losses, color = 'blue')\n",
    "plt.xlabel(\"epoch number\")\n",
    "plt.ylabel(\"training loss\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_array = []\n",
    "out_array = []\n",
    "err1 = 0\n",
    "err2 = 0\n",
    "err3 = 0\n",
    "tot = 0\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        # retrieve X and y for this batch, from data, and \n",
    "        # move it to the device you are using (probably the GPU)\n",
    "        X = data[0].to(device)\n",
    "        y = data[1].to(device)\n",
    "\n",
    "        # raw output of network for X\n",
    "        output = net(X)\n",
    "\n",
    "        a = torch.add(torch.mul(output[0], tstd.to(device)), tmean.to(device))\n",
    "        b = torch.add(torch.mul(y[0], tstd.to(device)), tmean.to(device))\n",
    "\n",
    "        print(\"###################################################\")\n",
    "        print(a)\n",
    "        print(b)\n",
    "        # print(output[0])\n",
    "        # print(y[0])\n",
    "        print(\"###################################################\")\n",
    "\n",
    "        hist_array.append(a.cpu().numpy() - b.cpu().numpy())\n",
    "        out_array.append(a.cpu().numpy())\n",
    "        \n",
    "        # let the maximum index be our predicted class\n",
    "        # _, yh = torch.max(output, 1) \n",
    "\n",
    "        # tot will 10,000 at the end, total number of test data\n",
    "        tot += y.size(0)\n",
    "\n",
    "        ## add to err number of missclassification, i.e. number of indices that \n",
    "        ## yh and y are not equal\n",
    "        ## note that y and yh are vectors of size = batch_size = (256 in our case)\n",
    "        # err += (y != yh).sum()\n",
    "\n",
    "        errors = output.sub(y).multiply(output.sub(y)).div(2).sum(axis=0)\n",
    "        err1 += errors[0]\n",
    "        err2 += errors[1]\n",
    "        err3 += errors[2]\n",
    "        count += 1\n",
    "\n",
    "print(tot)\n",
    "print(err1/count)\n",
    "print(err2/count)\n",
    "print(err3/count)\n",
    "\n",
    "print('Accuracy of prediction on test (1): %5.2f%%' % (100-100 * err1 / tot))\n",
    "\n",
    "print('Accuracy of prediction on test (2): %5.2f%%' % (100-100 * err2 / tot))\n",
    "\n",
    "print('Accuracy of prediction on test (3): %5.2f%%' % (100-100 * err3 / tot))\n",
    "\n",
    "###ASSERTS\n",
    "# assert((100-100 * err / tot)>=98)\n",
    "# assert(tot==10*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_array = np.array(hist_array)\n",
    "a = hist_array[:, 0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "ax.hist(a)\n",
    " \n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_array = np.array(out_array)\n",
    "a = out_array[:, 0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "ax.hist(a)\n",
    " \n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = hist_array[:, 1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "ax.hist(a)\n",
    " \n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = out_array[:, 1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "ax.hist(a)\n",
    " \n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = hist_array[:, 2]\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "ax.hist(a)\n",
    " \n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = out_array[:, 2]\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 7))\n",
    "ax.hist(a)\n",
    " \n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('../HMEI2023-bxliu-models/')\n",
    "# save_file = 'only_sigma.pt'\n",
    "# torch.save(net.state_dict(), save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torch.rand(1,1,128,128)\n",
    "test_net = ConvNet()\n",
    "out = test_net.forward(test_data)\n",
    "make_dot(out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Steps:\n",
    "custom loss function (later)\n",
    "documentation (done)\n",
    "validation (done-ish, needs going thru again with all the datasets probably)\n",
    "more data (done)\n",
    "graph outputs not just loss (done)\n",
    "outside training set for 5by400 and 10by200\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "f = '../HMEI2023-bxliu-data/image_rand_10by200/gentrain_1001.png'\n",
    "data = cv2.cvtColor(cv2.imread(f), cv2.COLOR_BGR2GRAY)\n",
    "data = cv2.resize(data, (128,128), interpolation=cv2.INTER_CUBIC)\n",
    "data = np.expand_dims(data, axis=2)\n",
    "print(data.shape)\n",
    "# out = net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=32768, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_net(im_data):\n",
    "    l = []\n",
    "    l.append(im_data)\n",
    "    l = np.asarray(l)\n",
    "    l = np.moveaxis(l, -1, 1)\n",
    "    print(l.shape)\n",
    "    l = torch.tensor(l).float()\n",
    "    l = torch.div(l, 255).float()\n",
    "    l = l.to(device)\n",
    "    print(l.shape)\n",
    "    print(l)\n",
    "    print(l.stride())\n",
    "    \n",
    "\n",
    "    with torch.no_grad():  \n",
    "        test_data = torch.rand(1,1,128,128).to(device)\n",
    "        test_data[0] = l[0]\n",
    "        print(test_data.shape)\n",
    "        print(test_data)\n",
    "        print(test_data.stride())\n",
    "        out = net.forward(test_data)\n",
    "        # out = net.forward(l)\n",
    "        out = torch.add(torch.mul(out[0], tstd.to(device)), tmean.to(device))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 128, 128)\n",
      "torch.Size([1, 1, 128, 128])\n",
      "tensor([[[[0.7294, 0.7451, 0.6000,  ..., 0.5216, 0.5569, 0.5529],\n",
      "          [0.7412, 0.7569, 0.6039,  ..., 0.5216, 0.5529, 0.5529],\n",
      "          [0.6314, 0.6392, 0.5686,  ..., 0.5373, 0.5725, 0.5686],\n",
      "          ...,\n",
      "          [0.3137, 0.2902, 0.5216,  ..., 0.3804, 0.8549, 0.8078],\n",
      "          [0.4902, 0.4980, 0.4275,  ..., 0.5373, 0.7176, 0.6980],\n",
      "          [0.4863, 0.4902, 0.4196,  ..., 0.5333, 0.7137, 0.6941]]]],\n",
      "       device='cuda:0')\n",
      "(16384, 1, 128, 1)\n",
      "torch.Size([1, 1, 128, 128])\n",
      "tensor([[[[0.7294, 0.7451, 0.6000,  ..., 0.5216, 0.5569, 0.5529],\n",
      "          [0.7412, 0.7569, 0.6039,  ..., 0.5216, 0.5529, 0.5529],\n",
      "          [0.6314, 0.6392, 0.5686,  ..., 0.5373, 0.5725, 0.5686],\n",
      "          ...,\n",
      "          [0.3137, 0.2902, 0.5216,  ..., 0.3804, 0.8549, 0.8078],\n",
      "          [0.4902, 0.4980, 0.4275,  ..., 0.5373, 0.7176, 0.6980],\n",
      "          [0.4863, 0.4902, 0.4196,  ..., 0.5333, 0.7137, 0.6941]]]],\n",
      "       device='cuda:0')\n",
      "(16384, 16384, 128, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2.0585e+06, 1.5562e+00, 6.0079e+03], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_net(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.34650214e+06 2.59287601e+00 4.98000000e+03]\n"
     ]
    }
   ],
   "source": [
    "matfile = '../HMEI2023-bxliu-data/value_rand_10by200/gentrain_1001.mat'\n",
    "mat = scipy.io.loadmat(matfile)\n",
    "print(mat['th0'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
